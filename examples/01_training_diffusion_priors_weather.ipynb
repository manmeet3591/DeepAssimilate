{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Diffusion Priors on Weather/Ocean Datasets\n",
        "\n",
        "This notebook demonstrates how to train an unconditional diffusion model on weather reanalysis data using the `diffusers` library. We'll use NCEP reanalysis 2-meter air temperature data as an example, but the approach generalizes to other weather/ocean variables.\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. **Data Loading**: Download and preprocess NCEP reanalysis data\n",
        "2. **Dataset Preparation**: Create PyTorch datasets with proper normalization\n",
        "3. **Model Setup**: Configure UNet2D model and noise scheduler\n",
        "4. **Training**: Train the diffusion model to learn the data distribution\n",
        "5. **Sampling**: Generate new samples from the trained model\n",
        "6. **Visualization**: Examine training progress and generated samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages if needed\n",
        "# Uncomment the lines below if running in a fresh environment\n",
        "# !pip install torch torchvision diffusers xarray netcdf4 matplotlib numpy tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import xarray as xr\n",
        "from tqdm import tqdm\n",
        "\n",
        "from diffusers import UNet2DModel, HeunDiscreteScheduler\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download and Load Weather Data\n",
        "\n",
        "We'll use NCEP reanalysis daily 2-meter air temperature data. This is publicly available from NOAA PSL.\n",
        "\n",
        "**Note**: You can modify the region selection (`lat`/`lon` slices) to focus on your area of interest (e.g., US, Europe).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download NCEP reanalysis data (example years)\n",
        "# Modify years as needed for your use case\n",
        "data_dir = \"data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "years = [\"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
        "base_url = \"https://downloads.psl.noaa.gov/Datasets/ncep.reanalysis/Dailies/surface_gauss/\"\n",
        "\n",
        "for year in years:\n",
        "    filename = f\"air.2m.gauss.{year}.nc\"\n",
        "    filepath = os.path.join(data_dir, filename)\n",
        "    \n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        os.system(f\"wget -q {base_url}{filename} -O {filepath}\")\n",
        "    else:\n",
        "        print(f\"{filename} already exists, skipping download.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and subset data\n",
        "# Example: US region (adjust lat/lon for your region of interest)\n",
        "# Format: lat=slice(lat_max, lat_min), lon=slice(lon_min, lon_max)\n",
        "# Note: Longitude is typically 0-360 for NCEP data\n",
        "\n",
        "# US region example\n",
        "lat_slice = slice(50, 25)  # Roughly 25N to 50N\n",
        "lon_slice = slice(235, 295)  # Roughly 235E (125W) to 295E (65W), i.e., 125W to 65W\n",
        "\n",
        "# Load training data (multiple years)\n",
        "train_files = [os.path.join(data_dir, f\"air.2m.gauss.{year}.nc\") for year in [\"2021\", \"2022\", \"2023\", \"2024\"]]\n",
        "ds_train = xr.open_mfdataset(train_files).sel(lat=lat_slice, lon=lon_slice)\n",
        "\n",
        "# Load validation and test data\n",
        "ds_valid = xr.open_dataset(os.path.join(data_dir, \"air.2m.gauss.2020.nc\")).sel(lat=lat_slice, lon=lon_slice)\n",
        "ds_test = xr.open_dataset(os.path.join(data_dir, \"air.2m.gauss.2019.nc\")).sel(lat=lat_slice, lon=lon_slice)\n",
        "\n",
        "print(f\"Training data shape: {ds_train.air.shape}\")\n",
        "print(f\"Spatial dimensions: {ds_train.air.isel(time=0).shape}\")\n",
        "print(f\"\\nCoordinate ranges:\")\n",
        "print(f\"  Latitude: {float(ds_train.lat.min()):.2f} to {float(ds_train.lat.max()):.2f}\")\n",
        "print(f\"  Longitude: {float(ds_train.lon.min()):.2f} to {float(ds_train.lon.max()):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize mean temperature field\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ds_train.mean(dim='time').air.plot(ax=ax, cmap='coolwarm')\n",
        "ax.set_title(\"Mean 2-meter Air Temperature (Training Period)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset and DataLoader Setup\n",
        "\n",
        "We'll create a PyTorch Dataset that:\n",
        "1. Extracts daily snapshots from the xarray dataset\n",
        "2. Normalizes the data to [0, 1] range (or [-1, 1] for some models)\n",
        "3. Reshapes to the format expected by UNet2D: `[C, H, W]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WeatherDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for weather reanalysis data.\n",
        "    \n",
        "    Args:\n",
        "        data: numpy array of shape [time, lat, lon] or xarray DataArray\n",
        "        normalize: tuple of (min, max) for normalization, or None to skip\n",
        "    \"\"\"\n",
        "    def __init__(self, data, normalize=None):\n",
        "        if isinstance(data, xr.DataArray):\n",
        "            data = data.values\n",
        "        \n",
        "        self.data = data.astype(np.float32)\n",
        "        \n",
        "        if normalize is None:\n",
        "            # Compute normalization from data\n",
        "            self.min = self.data.min()\n",
        "            self.max = self.data.max()\n",
        "        else:\n",
        "            self.min, self.max = normalize\n",
        "        \n",
        "        # Normalize to [0, 1]\n",
        "        self.data_norm = (self.data - self.min) / (self.max - self.min)\n",
        "        \n",
        "        print(f\"Dataset shape: {self.data_norm.shape}\")\n",
        "        print(f\"Value range: [{self.data_norm.min():.3f}, {self.data_norm.max():.3f}] (normalized)\")\n",
        "        print(f\"Original range: [{self.min:.2f}, {self.max:.2f}] (original units)\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data_norm)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Get single timestep: shape [lat, lon] -> [1, lat, lon] (add channel dim)\n",
        "        x = torch.from_numpy(self.data_norm[idx]).unsqueeze(0)\n",
        "        return x.float()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_data = ds_train.air.values\n",
        "valid_data = ds_valid.air.values\n",
        "test_data = ds_test.air.values\n",
        "\n",
        "# Normalize using training data statistics\n",
        "data_min, data_max = train_data.min(), train_data.max()\n",
        "\n",
        "train_dataset = WeatherDataset(train_data, normalize=(data_min, data_max))\n",
        "valid_dataset = WeatherDataset(valid_data, normalize=(data_min, data_max))\n",
        "test_dataset = WeatherDataset(test_data, normalize=(data_min, data_max))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataLoaders\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "# Check a batch\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"Batch shape: {sample_batch.shape}\")  # Should be [batch_size, 1, H, W]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a batch of training samples\n",
        "import torchvision\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "grid = torchvision.utils.make_grid(sample_batch[:8], nrow=4, padding=2)\n",
        "ax.imshow(grid[0].cpu().numpy(), cmap='coolwarm')\n",
        "ax.set_title(\"Sample Training Batch (8 random timesteps)\")\n",
        "ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model and Scheduler Setup\n",
        "\n",
        "We'll use a UNet2D model from diffusers with an EDM-style (Elucidating the Design Space of Diffusion-Based Generative Models) scheduler. The model learns to predict noise at different timesteps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determine image size from data\n",
        "_, _, img_h, img_w = sample_batch.shape\n",
        "img_size = max(img_h, img_w)  # UNet2D expects square or uses max dimension\n",
        "print(f\"Image size: {img_size} (height={img_h}, width={img_w})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize noise scheduler (EDM-style with Heun discretization)\n",
        "num_train_timesteps = 1000\n",
        "noise_scheduler = HeunDiscreteScheduler(num_train_timesteps=num_train_timesteps)\n",
        "\n",
        "print(f\"Scheduler: {type(noise_scheduler).__name__}\")\n",
        "print(f\"Number of training timesteps: {num_train_timesteps}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the noising process\n",
        "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "sample = sample_batch[0:1].to(device)  # [1, 1, H, W]\n",
        "\n",
        "# Map to [-1, 1] for visualization (EDM schedulers typically work in this range)\n",
        "sample = sample * 2.0 - 1.0\n",
        "\n",
        "# Show original\n",
        "axs[0].imshow(sample[0, 0].cpu().numpy(), cmap='coolwarm', vmin=-1, vmax=1)\n",
        "axs[0].set_title('Original (t=0)')\n",
        "axs[0].axis('off')\n",
        "\n",
        "# Add noise at different timesteps\n",
        "for i, timestep in enumerate([250, 500, 999]):\n",
        "    noise = torch.randn_like(sample)\n",
        "    timesteps = torch.tensor([timestep], device=device)\n",
        "    noisy = noise_scheduler.add_noise(sample, noise, timesteps)\n",
        "    \n",
        "    axs[i+1].imshow(noisy[0, 0].cpu().numpy(), cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    axs[i+1].set_title(f'Noisy (t={timestep})')\n",
        "    axs[i+1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize UNet2D model\n",
        "# Using a configuration similar to EDM models\n",
        "model = UNet2DModel(\n",
        "    sample_size=img_size,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    layers_per_block=2,\n",
        "    block_out_channels=(64, 128, 256, 512),\n",
        "    down_block_types=(\n",
        "        \"DownBlock2D\",\n",
        "        \"AttnDownBlock2D\",  # Attention layers help with spatial relationships\n",
        "        \"AttnDownBlock2D\",\n",
        "        \"DownBlock2D\",\n",
        "    ),\n",
        "    up_block_types=(\n",
        "        \"UpBlock2D\",\n",
        "        \"AttnUpBlock2D\",\n",
        "        \"AttnUpBlock2D\",\n",
        "        \"UpBlock2D\",\n",
        "    ),\n",
        "    time_embedding_type=\"positional\",  # or \"fourier\" for EDM-style\n",
        ").to(device)\n",
        "\n",
        "# Count parameters\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model initialized with {num_params:,} parameters\")\n",
        "print(f\"Model architecture: {type(model).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training Loop\n",
        "\n",
        "The training objective is to predict the noise that was added to the data:\n",
        "$$L = \\\\|\\\\epsilon - \\\\epsilon_\\\\theta(x_t, t)\\\\|^2$$\n",
        "\n",
        "where $x_t$ is the noisy input at timestep $t$, $\\\\epsilon$ is the true noise, and $\\\\epsilon_\\\\theta$ is the model prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "num_epochs = 20\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-2\n",
        "\n",
        "# Loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "\n",
        "# Learning rate scheduler (cosine annealing)\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=num_training_steps,\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "print(f\"Training for {num_epochs} epochs\")\n",
        "print(f\"Steps per epoch: {len(train_loader)}\")\n",
        "print(f\"Total training steps: {num_training_steps}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop with validation\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "checkpoint_dir = 'checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    epoch_train_losses = []\n",
        "    \n",
        "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "    for batch in train_pbar:\n",
        "        x = batch.to(device)  # [B, 1, H, W]\n",
        "        \n",
        "        # Map to [-1, 1] for EDM-style training\n",
        "        x = x * 2.0 - 1.0\n",
        "        \n",
        "        # Sample random timesteps\n",
        "        timesteps = torch.randint(\n",
        "            0,\n",
        "            noise_scheduler.num_train_timesteps,\n",
        "            (x.shape[0],),\n",
        "            device=device\n",
        "        ).long()\n",
        "        \n",
        "        # Add noise\n",
        "        noise = torch.randn_like(x)\n",
        "        noisy_x = noise_scheduler.add_noise(x, noise, timesteps)\n",
        "        \n",
        "        # Predict noise\n",
        "        pred_noise = model(noisy_x, timesteps).sample\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = loss_fn(pred_noise, noise)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        \n",
        "        epoch_train_losses.append(loss.item())\n",
        "        train_pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "    \n",
        "    avg_train_loss = np.mean(epoch_train_losses)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    \n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    epoch_val_losses = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        val_pbar = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Valid]\")\n",
        "        for batch in val_pbar:\n",
        "            x = batch.to(device)\n",
        "            x = x * 2.0 - 1.0\n",
        "            \n",
        "            timesteps = torch.randint(\n",
        "                0,\n",
        "                noise_scheduler.num_train_timesteps,\n",
        "                (x.shape[0],),\n",
        "                device=device\n",
        "            ).long()\n",
        "            \n",
        "            noise = torch.randn_like(x)\n",
        "            noisy_x = noise_scheduler.add_noise(x, noise, timesteps)\n",
        "            pred_noise = model(noisy_x, timesteps).sample\n",
        "            loss = loss_fn(pred_noise, noise)\n",
        "            \n",
        "            epoch_val_losses.append(loss.item())\n",
        "            val_pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "    \n",
        "    avg_val_loss = np.mean(epoch_val_losses)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    \n",
        "    # Print epoch summary\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.6f}\")\n",
        "    print(f\"  Val Loss: {avg_val_loss:.6f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': avg_val_loss,\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "        }, checkpoint_path)\n",
        "        print(f\"  âœ“ Saved best model (val_loss={avg_val_loss:.6f})\")\n",
        "    \n",
        "    print('-' * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(train_losses, label='Train Loss', marker='o')\n",
        "ax.plot(val_losses, label='Validation Loss', marker='s')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('MSE Loss')\n",
        "ax.set_title('Training Progress')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Sampling from the Trained Model\n",
        "\n",
        "Now we'll generate new samples by starting from pure noise and iteratively denoising using the trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "checkpoint = torch.load(os.path.join(checkpoint_dir, 'best_model.pth'))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "print(f\"Loaded model from epoch {checkpoint['epoch']+1} with val_loss={checkpoint['val_loss']:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate samples\n",
        "num_inference_steps = 50  # Number of denoising steps (can be reduced for faster sampling)\n",
        "num_samples = 4\n",
        "\n",
        "# Set timesteps for inference\n",
        "noise_scheduler.set_timesteps(num_inference_steps, device=device)\n",
        "\n",
        "# Start from random noise\n",
        "sample_shape = (num_samples, 1, img_h, img_w)\n",
        "samples = torch.randn(sample_shape, device=device)\n",
        "\n",
        "# Denoising loop\n",
        "with torch.no_grad():\n",
        "    for t in tqdm(noise_scheduler.timesteps, desc=\"Sampling\"):\n",
        "        # Expand timestep to batch size\n",
        "        timestep = t.expand(samples.shape[0])\n",
        "        \n",
        "        # Predict noise\n",
        "        noise_pred = model(samples, timestep).sample\n",
        "        \n",
        "        # Step scheduler\n",
        "        samples = noise_scheduler.step(noise_pred, t, samples).prev_sample\n",
        "\n",
        "# Map back to [0, 1] and then to original scale\n",
        "samples = (samples + 1.0) / 2.0  # [-1, 1] -> [0, 1]\n",
        "samples = samples * (data_max - data_min) + data_min  # Denormalize\n",
        "\n",
        "print(f\"Generated {num_samples} samples\")\n",
        "print(f\"Sample value range: [{samples.min():.2f}, {samples.max():.2f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize generated samples\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i in range(num_samples):\n",
        "    im = axs[i].imshow(samples[i, 0].cpu().numpy(), cmap='coolwarm')\n",
        "    axs[i].set_title(f'Generated Sample {i+1}')\n",
        "    axs[i].axis('off')\n",
        "    plt.colorbar(im, ax=axs[i], fraction=0.046)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare with real data\n",
        "fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
        "\n",
        "# Real samples from test set\n",
        "real_samples = test_dataset[:num_samples]\n",
        "real_samples_tensor = torch.stack(real_samples) * (data_max - data_min) + data_min\n",
        "\n",
        "for i in range(num_samples):\n",
        "    # Generated\n",
        "    im1 = axs[0, i].imshow(samples[i, 0].cpu().numpy(), cmap='coolwarm')\n",
        "    axs[0, i].set_title(f'Generated {i+1}')\n",
        "    axs[0, i].axis('off')\n",
        "    plt.colorbar(im1, ax=axs[0, i], fraction=0.046)\n",
        "    \n",
        "    # Real\n",
        "    im2 = axs[1, i].imshow(real_samples_tensor[i, 0].cpu().numpy(), cmap='coolwarm')\n",
        "    axs[1, i].set_title(f'Real {i+1}')\n",
        "    axs[1, i].axis('off')\n",
        "    plt.colorbar(im2, ax=axs[1, i], fraction=0.046)\n",
        "\n",
        "plt.suptitle('Generated vs Real Samples', fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps\n",
        "\n",
        "Congratulations! You've trained a diffusion model on weather data. Here are some next steps:\n",
        "\n",
        "1. **Generative Data Assimilation**: Use the trained model with observations to improve initial conditions. See the `02_generative_data_assimilation.ipynb` notebook.\n",
        "\n",
        "2. **Experiment with Different Regions**: Train models on different regions (Europe, global, etc.) or different variables (precipitation, winds, etc.).\n",
        "\n",
        "3. **Architecture Improvements**: Try different UNet configurations, add attention mechanisms, or experiment with Diffusion Transformers (DiT).\n",
        "\n",
        "4. **Distillation**: Use scheduler-only distillation to reduce inference timesteps for faster sampling.\n",
        "\n",
        "5. **Evaluation Metrics**: Add quantitative evaluation (e.g., distribution statistics, spatial correlation, spectral properties).\n",
        "\n",
        "6. **High-Resolution Models**: Extend to higher resolutions using latent diffusion models or tile-based approaches.\n",
        "\n",
        "## Using deepassimilate Library\n",
        "\n",
        "You can also use the `deepassimilate` library's training function for a more streamlined workflow:\n",
        "\n",
        "```python\n",
        "import deepassimilate as da\n",
        "\n",
        "cfg = da.UncondTrainConfig(\n",
        "    architecture=\"edm_unet_2d\",\n",
        "    scheduler=\"heun_edm\",\n",
        "    img_size=64,\n",
        "    channels=1,\n",
        "    num_epochs=20,\n",
        "    batch_size=16,\n",
        "    lr=1e-4,\n",
        "    device=\"cuda\"\n",
        ")\n",
        "\n",
        "model, scheduler, distilled_steps = da.train_unconditional(\n",
        "    dataset=train_dataset,\n",
        "    cfg=cfg\n",
        ")\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
